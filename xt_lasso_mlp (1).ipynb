{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "# If pandas is not installed, please uncomment the following line:\n",
    "#!pip install pandas\n",
    "#!pip install sklearn\n",
    "#!pip install pathos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full\n",
    "\n",
    "def read_mimic_csv(path):\n",
    "    start = time.time()\n",
    "    TextFileReader = pd.read_csv(path, chunksize=100000, iterator=True, low_memory=False)\n",
    "    df = pd.concat(TextFileReader, ignore_index=True)\n",
    "    print(path, \":\" , round(time.time() - start, 1), 'seconds')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../payload/PATIENTS.csv : 0.1 seconds\n",
      "../../payload/DIAGNOSES_ICD.csv : 0.3 seconds\n",
      "../../payload/ADMISSIONS.csv : 0.3 seconds\n"
     ]
    }
   ],
   "source": [
    "path = '../../payload/' # change as needed\n",
    "patients = read_mimic_csv(path + 'PATIENTS.csv')\n",
    "diagnoses = read_mimic_csv(path + 'DIAGNOSES_ICD.csv')\n",
    "admissions = read_mimic_csv(path + 'ADMISSIONS.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs = open(\"../../payload/ccs.txt\", \"r\").read()\n",
    "\n",
    "# Create dictionary. Key is ICD9 code for a diagnosis. Value is general description of diagnosis.\n",
    "ccs = ccs[ccs.find('Tuberculosis'):]\n",
    "icd9={}\n",
    "\n",
    "def update_icd9(cur_value, section):\n",
    "    while section:\n",
    "        if section[:4] == '\\n\\n':\n",
    "            print('new value')\n",
    "            section = section[4:]\n",
    "            cur_value = section[:section.find('\\n')]\n",
    "            section = section[section.find('\\n'):]\n",
    "        elif section[0] == ' ':\n",
    "            section = section[1:]\n",
    "        elif section[:2] == '\\n':\n",
    "            section = section[2:]\n",
    "        else:\n",
    "            if section.find(' ') >= 0: # not end of document\n",
    "                if -1 < section.find('\\n') < section.find(' '): # if end of line\n",
    "                    cur_key = section[:section.find('\\n')]\n",
    "                else: # if not end of line\n",
    "                    cur_key = section[:section.find(' ')]\n",
    "                section = section[section.find(' '):]\n",
    "                icd9[cur_key] = cur_value\n",
    "\n",
    "            else: # end of section\n",
    "                cur_key = section\n",
    "                icd9[cur_key] = cur_value\n",
    "                section = \"\"\n",
    "            \n",
    "for section in ccs.split(sep='\\n\\n'): # for each family of codes\n",
    "    cur_value = section[:section.find('\\n')] # get the name for that family\n",
    "    section = section[section.find('\\n')+1:] # and for all the codes under that family\n",
    "    update_icd9(cur_value, section) # add those codes as keys to a dictionary, where their values\n",
    "                                    # are the name for the family of codes\n",
    "\n",
    "diagnoses.ICD9_CODE = diagnoses.ICD9_CODE.apply(lambda x: icd9.get(x,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create LOS feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = admissions[['SUBJECT_ID',\n",
    "                 'HADM_ID',\n",
    "                 'ADMISSION_TYPE',\n",
    "                 'ADMITTIME']].copy()\n",
    "\n",
    "df['LOS'] = (pd.to_datetime(admissions['DISCHTIME']) - pd.to_datetime(admissions['ADMITTIME'])).astype('timedelta64[h]') \n",
    "df['ADMITTIME'] = pd.to_datetime(admissions['ADMITTIME']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['LOS'] >= 0]\n",
    "diagnoses = pd.get_dummies(diagnoses[['HADM_ID','ICD9_CODE']], drop_first=False)\n",
    "diagnoses = diagnoses.groupby('HADM_ID').agg('sum')\n",
    "df = pd.merge(df, diagnoses, on='HADM_ID', how='left') \n",
    "# For mortality classification, I'm keeping DOD_HOSP so I can create a boolean response for death\n",
    "# NB: DOD includes ALL deaths (before & after), while DOD_HOSP only includes deaths occuring inside the hospital. \n",
    "df = pd.merge(df, # drop DOD_HOSP too if not classifying mortality\n",
    "              patients.drop(columns = ['DOD', 'DOD_SSN','ROW_ID','EXPIRE_FLAG']),\n",
    "              on='SUBJECT_ID',\n",
    "              how='left') \n",
    "\n",
    "median_dob_shift = 300 - 91.4 # For old patients (median age of 91.4), dob was shifted to be 300 yrs prior to first visit\n",
    "df['AGE'] = (pd.to_datetime(df['ADMITTIME']).dt.date - pd.to_datetime(df['DOB']).dt.date)\n",
    "df['AGE'] = [age.days/365 if age.days/365<300 else age.days/365-median_dob_shift for age in df['AGE']]\n",
    "\n",
    "df['DIED'] = df['DOD_HOSP'].apply(lambda x: not pd.isnull(x))\n",
    "\n",
    "df['ADMITHOUR_trig_x'] = pd.to_datetime(df['ADMITTIME']).dt.hour.apply(math.cos)\n",
    "df['ADMITHOUR_trig_y'] = pd.to_datetime(df['ADMITTIME']).dt.hour.apply(math.sin)\n",
    "df['ADMITHOUR'] = pd.to_datetime(df['ADMITTIME']).dt.hour\n",
    "\n",
    "df.drop(['DOD_HOSP','DOB'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before adding dummy variables: (58878, 293)\n",
      "Shape after adding dummy variables: (58878, 295)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before adding dummy variables:',df.shape)\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "print('Shape after adding dummy variables:', df.shape)\n",
    "\n",
    "# It turns out ADMITHOUR after trig transform is highly predictive of whether you die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_day_chartevents.csv : 0.2 seconds\n"
     ]
    }
   ],
   "source": [
    "first_chartevents = read_mimic_csv('first_day_chartevents.csv')\n",
    "first_chartevents = first_chartevents.drop(columns = [\"Unnamed: 0\"])\n",
    "df = pd.merge(df, first_chartevents, on='HADM_ID',\n",
    "              how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_serv_pres_micro.csv : 0.4 seconds\n"
     ]
    }
   ],
   "source": [
    "# mandi's merged tables\n",
    "first_serv_pres_micro = read_mimic_csv('first_serv_pres_micro.csv')\n",
    "first_serv_pres_micro = first_serv_pres_micro.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "hadm = first_serv_pres_micro.index.values\n",
    "first_serv_pres_micro['HADM_ID'] = hadm\n",
    "\n",
    "df = pd.merge(df, first_serv_pres_micro, on=\"HADM_ID\", how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using MXNet backend\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "%matplotlib inline\n",
    "#import d2l\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = df\n",
    "df_demo.drop([col for col, val in df_demo.sum().iteritems() if type(val) == int and val < 2], axis=1, inplace=True)\n",
    "df_demo.shape\n",
    "\n",
    "df_demo = df_demo.drop(columns = [\"SUBJECT_ID\",\"ADMITTIME\"])\n",
    "df_demo = df_demo.fillna(0)\n",
    "\n",
    "\n",
    "X = df_demo.iloc[:,3:]\n",
    "y = df_demo.iloc[:,1]\n",
    "X_train_demo, X_test_demo, y_train_demo, y_test_demo = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.871938228607178"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "#alphas = np.array([-1, -0.1 , 0.01, 0.1, 1, 10 , 100])\n",
    "alphas = np.array([-1, 1, 10])\n",
    "\n",
    "lassocv = linear_model.LassoCV(cv = 5, normalize=True)\n",
    "lassocv.fit(X, y)\n",
    "lassocv_score = lassocv.score(X, y)\n",
    "lassocv_alpha = lassocv.alpha_\n",
    "\n",
    "time.time() - time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.4384892353893367\n",
      "test score:  0.44207843976031624\n",
      "number of features used:  287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.034797668457031"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "lasso = Lasso(alpha = lassocv_alpha)#, max_iter = 10e6)\n",
    "lasso.fit(X_train_demo, y_train_demo)\n",
    "train_score = lasso.score(X_train_demo, y_train_demo)\n",
    "test_score = lasso.score(X_test_demo, y_test_demo)\n",
    "coef_used = np.sum(lasso.coef_ != 0)\n",
    "\n",
    "print('training score: ', train_score)\n",
    "print('test score: ', test_score)\n",
    "print('number of features used: ', coef_used)\n",
    "\n",
    "time.time() - time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = []\n",
    "\n",
    "used = []\n",
    "\n",
    "for i in range(len(lasso.coef_ )):\n",
    "    if lasso.coef_[i] == 0:\n",
    "        zeros += [i]\n",
    "    else:\n",
    "        used += [i]\n",
    "\n",
    "#test to see what it looks like:\n",
    "#X.iloc[0:10, used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "filtered = X.iloc[:, used]\n",
    "filtered['LOS'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If pandas is not installed, please uncomment the following line:\n",
    "#!pip install pandas\n",
    "#!pip install sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = pd.read_pickle('bert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df = pd.merge(df_demo, bert, on='HADM_ID',\n",
    "              how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df['VEC'] = bert_df['VEC'].apply(lambda d: d if isinstance(d, np.ndarray) else [[0]]*768)\n",
    "bert_df = pd.merge(bert_df.iloc[:,:-1], \n",
    "                   pd.DataFrame(bert_df.VEC.values.tolist(), index= bert_df.HADM_ID).applymap(lambda x: x[0]),\n",
    "                   on='HADM_ID',\n",
    "                   how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post lasso data\n",
    "#filtered = pd.read_csv('filtered.csv') \n",
    "filtered = pd.concat([bert_df.iloc[:,used], bert_df.iloc[:,-768:]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if when u run lasso, there are different number of features,\n",
    "# just put labels as last column below.\n",
    "X = filtered.drop(columns = ['LOS','DIED','HADM_ID'])\n",
    "y = filtered['LOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, RidgeCV, LogisticRegressionCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression(normalize=True, n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45239766381972435"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([109.00247928, 339.76167537, 382.77892417, ..., 244.81552879,\n",
       "       376.85231438, 235.45917388])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = linreg.predict(X_train)\n",
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219.73166231978817"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(train_pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110779.79531933692"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_acc(preds, y_t):\n",
    "    predictions = preds.reshape(len(y_t),)\n",
    "    difference = predictions - y_t\n",
    "    threshold_15 = 0.15*y_t\n",
    "    acc_test_15 = sum(threshold_15 - abs(difference) > 0) / len(y_t)\n",
    "    print('test accuracy: ', acc_test_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.16990785953887308\n",
      "test accuracy:  0.15692934782608695\n"
     ]
    }
   ],
   "source": [
    "get_threshold_acc(train_pred, y_train)\n",
    "get_threshold_acc(test_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rid = RidgeCV(normalize=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43900771962417673"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rid.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222.40187160516433"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = rid.predict(X_train)\n",
    "math.sqrt(mean_squared_error(train_pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231.47335010722162"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = rid.predict(X_test)\n",
    "math.sqrt(mean_squared_error(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.164281771474672\n",
      "test accuracy:  0.15879755434782608\n"
     ]
    }
   ],
   "source": [
    "get_threshold_acc(train_pred, y_train)\n",
    "get_threshold_acc(test_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv = linear_model.LassoCV(cv = 5, normalize=True)\n",
    "lassocv.fit(X, y)\n",
    "lassocv_score = lassocv.score(X, y)\n",
    "lassocv_alpha = lassocv.alpha_\n",
    "lasso = Lasso(alpha = lassocv_alpha)#, max_iter = 10e6)\n",
    "lasso.fit(X_train_demo, y_train_demo)\n",
    "train_score = lasso.score(X_train_demo, y_train_demo)\n",
    "test_score = lasso.score(X_test_demo, y_test_demo)\n",
    "coef_used = np.sum(lasso.coef_ != 0)\n",
    "zeros = []\n",
    "\n",
    "used = []\n",
    "\n",
    "for i in range(len(lasso.coef_ )):\n",
    "    if lasso.coef_[i] == 0:\n",
    "        zeros += [i]\n",
    "    else:\n",
    "        used += [i]\n",
    "filtered = X.iloc[:, used]\n",
    "filtered = pd.concat([bert_df.iloc[:,used], bert_df.iloc[:,-768:]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = filtered['DIED']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7461891214810411"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegressionCV(Cs=[.01,.1,1,10], fit_intercept=True, cv=5, random_state=0).fit(X_train,y_train)\n",
    "log.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426120923913043"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.745473691361799"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - sum(y)/len(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
