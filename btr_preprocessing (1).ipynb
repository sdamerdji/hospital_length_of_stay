{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from scipy import stats\n",
    "import math\n",
    "from sklearn.pipeline import Pipeline\n",
    "# If pandas is not installed, please uncomment the following line:\n",
    "#!pip install pandas\n",
    "#!pip install sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mimic(file, dict_of_str_cols):\n",
    "    col_names = pd.read_csv(file, nrows=0).columns\n",
    "    dict_of_str_cols.update({col: object for col in col_names if col not in dict_of_str_cols})\n",
    "    return pd.read_csv(file, dtype=dict_of_str_cols, low_memory=False, nrows=100000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "charts = pd.read_csv(path + 'CHARTEVENTS.csv', nrows=100000000)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "read_mimic(path + 'CHARTEVENTS.csv', numeric_cols)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full\n",
    "path = \"payload/\" # change as needed\n",
    "numeric_cols = {'ROW_ID':float,\n",
    "                'SUBJECT_ID':float,\n",
    "                'HADM_ID':float,\n",
    "                'HAS_CHARTEVENTS_DATA':float,\n",
    "                'HOSPITAL_EXPIRE_FLAG':float,\n",
    "                'EXPIRE_FLAG':float,\n",
    "                'SEQ_NUM':float,\n",
    "                'ITEMID':float,\n",
    "                'AMOUNT':float, \n",
    "                'RATE':float, \n",
    "                'RATEUOM':float,\n",
    "                'CGID':float,\n",
    "                'ORDERID':float,\n",
    "                'LINKORDERID':float,\n",
    "                'STOPPED':float,\n",
    "                'NEWBOTTLE':float,\n",
    "                'ORIGINALAMOUNT':float,\n",
    "                'ORIGINALRATE':float,\n",
    "                'ORIGINALRATEUOM':float,\n",
    "                'ORIGINALSITE':float,\n",
    "                'VALUENUM':float,\n",
    "                'CGID':float,\n",
    "                'ISERROR':float,\n",
    "                #'STORETIME':float, # could be wrong\n",
    "                #'CHARTTIME':float, # could be wrong\n",
    "                'RESULTSTATUS':float,\n",
    "                'STOPPED': float,\n",
    "                'WARNING':float,\n",
    "                'ERROR':float,\n",
    "                'VALUENUM':float,\n",
    "                'ICUSTAY_ID':float} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_csv(path + 'PATIENTS.csv')\n",
    "print('Patients')\n",
    "diagnoses = pd.read_csv(path + 'DIAGNOSES_ICD.csv')\n",
    "print('Diagnoses')\n",
    "input_cv = pd.read_csv(path + 'INPUTEVENTS_CV.csv')\n",
    "print('Input_cv')\n",
    "input_mv = pd.read_csv(path + 'INPUTEVENTS_MV.csv')\n",
    "print('Input_mv')\n",
    "chartevents = pd.read_csv(path + 'CHARTEVENTS.csv', low_memory=False)\n",
    "print('Chartevents')\n",
    "labevents = pd.read_csv(path + 'MICROBIOLOGYEVENTS.csv')\n",
    "print('Microbiology')\n",
    "prescriptions = pd.read_csv(path + 'PRESCRIPTIONS.csv')\n",
    "print('Prescriptions')\n",
    "procedureevents = pd.read_csv(path + 'PROCEDUREEVENTS_MV.csv')\n",
    "print('Procedure Events MV')\n",
    "procedures_icd = pd.read_csv(path + 'PROCEDURES_ICD.csv')\n",
    "print('Procedure Events ICD')\n",
    "services = pd.read_csv(path + 'SERVICES.csv') \n",
    "print('Services')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICD9 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs = open(\"ccs.txt\", \"r\").read()\n",
    "\n",
    "# Create dictionary. Key is ICD9 code for a diagnosis. Value is general description of diagnosis.\n",
    "ccs = ccs[ccs.find('Tuberculosis'):]\n",
    "icd9={}\n",
    "\n",
    "def update_icd9(cur_value, section):\n",
    "    while section:\n",
    "        if section[:4] == '\\n\\n':\n",
    "            print('new value')\n",
    "            section = section[4:]\n",
    "            cur_value = section[:section.find('\\n')]\n",
    "            section = section[section.find('\\n'):]\n",
    "        elif section[0] == ' ':\n",
    "            section = section[1:]\n",
    "        elif section[:2] == '\\n':\n",
    "            section = section[2:]\n",
    "        else:\n",
    "            if section.find(' ') >= 0: # not end of document\n",
    "                if -1 < section.find('\\n') < section.find(' '): # if end of line\n",
    "                    cur_key = section[:section.find('\\n')]\n",
    "                else: # if not end of line\n",
    "                    cur_key = section[:section.find(' ')]\n",
    "                section = section[section.find(' '):]\n",
    "                icd9[cur_key] = cur_value\n",
    "\n",
    "            else: # end of section\n",
    "                cur_key = section\n",
    "                icd9[cur_key] = cur_value\n",
    "                section = \"\"\n",
    "            \n",
    "for section in ccs.split(sep='\\n\\n'): # for each family of codes\n",
    "    cur_value = section[:section.find('\\n')] # get the name for that family\n",
    "    section = section[section.find('\\n')+1:] # and for all the codes under that family\n",
    "    update_icd9(cur_value, section) # add those codes as keys to a dictionary, where their values\n",
    "                                    # are the name for the family of codes\n",
    "\n",
    "diagnoses.ICD9_CODE = diagnoses.ICD9_CODE.apply(lambda x: icd9.get(x,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create LOS feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# commented out for mortality classification:\n",
    "# admissions = admissions[pd.isnull(admissions['DEATHTIME'])]\n",
    "df = admissions[['SUBJECT_ID',\n",
    "                 'HADM_ID',\n",
    "                 'ADMISSION_TYPE',\n",
    "                 'ADMITTIME',\n",
    "                 'ADMISSION_LOCATION',\n",
    "                 'INSURANCE',\n",
    "                 'LANGUAGE',\n",
    "                 'RELIGION',\n",
    "                 'MARITAL_STATUS',\n",
    "                 'ETHNICITY']].copy()\n",
    "\n",
    "df = pd.merge(df, # drop DOD_HOSP too if not classifying mortality\n",
    "              diagnoses.drop(columns = ['SEQ_NUM','SUBJECT_ID']),\n",
    "              on='HADM_ID',\n",
    "              how='left') \n",
    "\n",
    "df['LOS'] = (pd.to_datetime(admissions['DISCHTIME']) - pd.to_datetime(admissions['ADMITTIME'])).astype('timedelta64[h]') \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self: There are negative LOS values for when a patient dies prior to arriving to the hospital. I keep these in for mortality classification. But these values kinda lead to meaningless LOS values.\n",
    "\n",
    "#### Extracting age feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For mortality classification, I'm keeping DOD_HOSP so I can create a boolean response for death\n",
    "# NB: DOD includes ALL deaths (before & after), while DOD_HOSP only includes deaths occuring inside the hospital. \n",
    "df = pd.merge(df, # drop DOD_HOSP too if not classifying mortality\n",
    "              patients.drop(columns = ['DOD', 'DOD_SSN','ROW_ID','EXPIRE_FLAG']),\n",
    "              on='SUBJECT_ID',\n",
    "              how='left') \n",
    "median_dob_shift = 300 - 91.4 # For old patients (median age of 91.4), dob was shifted to be 300 yrs prior to first visit\n",
    "df['AGE'] = (pd.to_datetime(df['ADMITTIME']).dt.date - pd.to_datetime(df['DOB']).dt.date)\n",
    "df['AGE'] = [age.days/365 if age.days/365<300 else age.days/365-median_dob_shift for age in df['AGE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting whether-they-died feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['DIED'] = df['DOD_HOSP'].apply(lambda x: not pd.isnull(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trig transform for admit time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADMITHOUR_trig_x'] = pd.to_datetime(df['ADMITTIME']).dt.hour.apply(math.cos)\n",
    "df['ADMITHOUR_trig_y'] = pd.to_datetime(df['ADMITTIME']).dt.hour.apply(math.sin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Christine's features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['DOB', 'DOD_HOSP','ADMITTIME','SUBJECT_ID','HADM_ID','ROW_ID'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"DOB is the date of birth of the given patient. Patients who are older than 89 years old at any time in the database have had their date of birth shifted to obscure their age and comply with HIPAA. The shift process was as follows: the patient’s age at their first admission was determined. The date of birth was then set to exactly 300 years before their first admission\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ADMISSION_TYPE', 'ADMISSION_LOCATION', 'INSURANCE', 'LANGUAGE',\n",
       "       'RELIGION', 'MARITAL_STATUS', 'ETHNICITY', 'ICD9_CODE', 'LOS', 'GENDER',\n",
       "       'AGE', 'DIED', 'ADMITHOUR_trig_x', 'ADMITHOUR_trig_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy variables and drop those with less information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before adding dummy variables: (651047, 14)\n",
      "Shape after adding dummy variables: (651047, 441)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before adding dummy variables:',df.shape)\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "print('Shape after adding dummy variables:', df.shape)\n",
    "#df.drop([col for col, val in df.sum().iteritems() if val < 10], axis=1, inplace=True)\n",
    "#print('Shape after dropping columns with few observations:', df.shape)\n",
    "\n",
    "# It turns out ADMITHOUR after trig transform is highly predictive of whether you die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df.drop(['LOS'],axis=1)\n",
    "X= df_pred.drop(['DIED',],axis=1)\n",
    "y= df_pred['DIED']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline created\n",
      "Pipeline fit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7073343061208817"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler',preprocessing.StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "print('Pipeline created')\n",
    "pipeline.fit(X_train,y_train)\n",
    "print('Pipeline fit')\n",
    "pipeline.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022048997772828538"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7073343061208817 - (1-sum(y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                                                                               0.252403\n",
       "INSURANCE_Medicare                                                                0.195332\n",
       "ADMISSION_TYPE_EMERGENCY                                                          0.184657\n",
       "ADMISSION_TYPE_NEWBORN                                                            0.178849\n",
       "ADMISSION_LOCATION_EMERGENCY ROOM ADMIT                                           0.149062\n",
       "INSURANCE_Private                                                                 0.146854\n",
       "ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI                                      0.137990\n",
       "RELIGION_JEWISH                                                                   0.095305\n",
       "ICD9_CODE_224  Other perinatal conditions                                         0.083662\n",
       "MARITAL_STATUS_WIDOWED                                                            0.082550\n",
       "ICD9_CODE_42   Secondary malignancies                                             0.079806\n",
       "ICD9_CODE_218  Liveborn                                                           0.072870\n",
       "INSURANCE_Medicaid                                                                0.069477\n",
       "MARITAL_STATUS_MARRIED                                                            0.065088\n",
       "ICD9_CODE_219  Short gestation; low birth weight; and fetal growth retardation    0.064296\n",
       "ICD9_CODE_256  Medical examination/evaluation                                     0.064206\n",
       "ICD9_CODE_10   Immunizations and screening for infectious disease                 0.062117\n",
       "RELIGION_NOT SPECIFIED                                                            0.058341\n",
       "ADMISSION_LOCATION_CLINIC REFERRAL/PREMATURE                                      0.052332\n",
       "RELIGION_UNOBTAINABLE                                                             0.051300\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.apply(lambda x: abs(x.corr(y_train))).sort_values(ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
