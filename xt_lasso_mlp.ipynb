{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "# If pandas is not installed, please uncomment the following line:\n",
    "#!pip install pandas\n",
    "#!pip install sklearn\n",
    "#!pip install pathos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full\n",
    "\n",
    "def read_mimic_csv(path):\n",
    "    start = time.time()\n",
    "    TextFileReader = pd.read_csv(path, chunksize=100000, iterator=True, low_memory=False)\n",
    "    df = pd.concat(TextFileReader, ignore_index=True)\n",
    "    print(path, \":\" , round(time.time() - start, 1), 'seconds')\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../payload/PATIENTS.csv : 0.1 seconds\n",
      "../../payload/DIAGNOSES_ICD.csv : 0.3 seconds\n",
      "../../payload/ADMISSIONS.csv : 0.3 seconds\n"
     ]
    }
   ],
   "source": [
    "path = '../../payload/' # change as needed\n",
    "patients = read_mimic_csv(path + 'PATIENTS.csv')\n",
    "diagnoses = read_mimic_csv(path + 'DIAGNOSES_ICD.csv')\n",
    "admissions = read_mimic_csv(path + 'ADMISSIONS.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs = open(\"../../payload/ccs.txt\", \"r\").read()\n",
    "\n",
    "# Create dictionary. Key is ICD9 code for a diagnosis. Value is general description of diagnosis.\n",
    "ccs = ccs[ccs.find('Tuberculosis'):]\n",
    "icd9={}\n",
    "\n",
    "def update_icd9(cur_value, section):\n",
    "    while section:\n",
    "        if section[:4] == '\\n\\n':\n",
    "            print('new value')\n",
    "            section = section[4:]\n",
    "            cur_value = section[:section.find('\\n')]\n",
    "            section = section[section.find('\\n'):]\n",
    "        elif section[0] == ' ':\n",
    "            section = section[1:]\n",
    "        elif section[:2] == '\\n':\n",
    "            section = section[2:]\n",
    "        else:\n",
    "            if section.find(' ') >= 0: # not end of document\n",
    "                if -1 < section.find('\\n') < section.find(' '): # if end of line\n",
    "                    cur_key = section[:section.find('\\n')]\n",
    "                else: # if not end of line\n",
    "                    cur_key = section[:section.find(' ')]\n",
    "                section = section[section.find(' '):]\n",
    "                icd9[cur_key] = cur_value\n",
    "\n",
    "            else: # end of section\n",
    "                cur_key = section\n",
    "                icd9[cur_key] = cur_value\n",
    "                section = \"\"\n",
    "            \n",
    "for section in ccs.split(sep='\\n\\n'): # for each family of codes\n",
    "    cur_value = section[:section.find('\\n')] # get the name for that family\n",
    "    section = section[section.find('\\n')+1:] # and for all the codes under that family\n",
    "    update_icd9(cur_value, section) # add those codes as keys to a dictionary, where their values\n",
    "                                    # are the name for the family of codes\n",
    "\n",
    "diagnoses.ICD9_CODE = diagnoses.ICD9_CODE.apply(lambda x: icd9.get(x,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create LOS feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = admissions[['SUBJECT_ID',\n",
    "                 'HADM_ID',\n",
    "                 'ADMISSION_TYPE',\n",
    "                 'ADMITTIME']].copy()\n",
    "\n",
    "df['LOS'] = (pd.to_datetime(admissions['DISCHTIME']) - pd.to_datetime(admissions['ADMITTIME'])).astype('timedelta64[h]') \n",
    "df['ADMITTIME'] = pd.to_datetime(admissions['ADMITTIME']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['LOS'] >= 0]\n",
    "diagnoses = pd.get_dummies(diagnoses[['HADM_ID','ICD9_CODE']], drop_first=False)\n",
    "diagnoses = diagnoses.groupby('HADM_ID').agg('sum')\n",
    "df = pd.merge(df, diagnoses, on='HADM_ID', how='left') \n",
    "# For mortality classification, I'm keeping DOD_HOSP so I can create a boolean response for death\n",
    "# NB: DOD includes ALL deaths (before & after), while DOD_HOSP only includes deaths occuring inside the hospital. \n",
    "df = pd.merge(df, # drop DOD_HOSP too if not classifying mortality\n",
    "              patients.drop(columns = ['DOD', 'DOD_SSN','ROW_ID','EXPIRE_FLAG']),\n",
    "              on='SUBJECT_ID',\n",
    "              how='left') \n",
    "\n",
    "median_dob_shift = 300 - 91.4 # For old patients (median age of 91.4), dob was shifted to be 300 yrs prior to first visit\n",
    "df['AGE'] = (pd.to_datetime(df['ADMITTIME']).dt.date - pd.to_datetime(df['DOB']).dt.date)\n",
    "df['AGE'] = [age.days/365 if age.days/365<300 else age.days/365-median_dob_shift for age in df['AGE']]\n",
    "\n",
    "df['DIED'] = df['DOD_HOSP'].apply(lambda x: not pd.isnull(x))\n",
    "\n",
    "df['ADMITHOUR_trig_x'] = pd.to_datetime(df['ADMITTIME']).dt.hour.apply(math.cos)\n",
    "df['ADMITHOUR_trig_y'] = pd.to_datetime(df['ADMITTIME']).dt.hour.apply(math.sin)\n",
    "df['ADMITHOUR'] = pd.to_datetime(df['ADMITTIME']).dt.hour\n",
    "\n",
    "df.drop(['DOD_HOSP','DOB'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before adding dummy variables: (58878, 293)\n",
      "Shape after adding dummy variables: (58878, 295)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before adding dummy variables:',df.shape)\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "print('Shape after adding dummy variables:', df.shape)\n",
    "\n",
    "# It turns out ADMITHOUR after trig transform is highly predictive of whether you die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_day_chartevents.csv : 0.2 seconds\n"
     ]
    }
   ],
   "source": [
    "first_chartevents = read_mimic_csv('first_day_chartevents.csv')\n",
    "first_chartevents = first_chartevents.drop(columns = [\"Unnamed: 0\"])\n",
    "df = pd.merge(df, first_chartevents, on='HADM_ID',\n",
    "              how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_serv_pres_micro.csv : 0.4 seconds\n"
     ]
    }
   ],
   "source": [
    "# mandi's merged tables\n",
    "first_serv_pres_micro = read_mimic_csv('first_serv_pres_micro.csv')\n",
    "first_serv_pres_micro = first_serv_pres_micro.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "hadm = first_serv_pres_micro.index.values\n",
    "first_serv_pres_micro['HADM_ID'] = hadm\n",
    "\n",
    "df = pd.merge(df, first_serv_pres_micro, on=\"HADM_ID\", how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "%matplotlib inline\n",
    "#import d2l\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_demo = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo.drop([col for col, val in df_demo.sum().iteritems() if type(val) == int and val < 2], axis=1, inplace=True)\n",
    "df_demo.shape\n",
    "\n",
    "df_demo = df_demo.drop(columns = [\"SUBJECT_ID\",\"ADMITTIME\"])\n",
    "df_demo = df_demo.fillna(0)\n",
    "\n",
    "\n",
    "X = df_demo.iloc[:,3:]\n",
    "y = df_demo.iloc[:,1]\n",
    "X_train_demo, X_test_demo, y_train_demo, y_test_demo = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.702288627624512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "#alphas = np.array([-1, -0.1 , 0.01, 0.1, 1, 10 , 100])\n",
    "alphas = np.array([-1, 1, 10])\n",
    "\n",
    "lassocv = linear_model.LassoCV(cv = 5)\n",
    "lassocv.fit(X, y)\n",
    "lassocv_score = lassocv.score(X, y)\n",
    "lassocv_alpha = lassocv.alpha_\n",
    "\n",
    "time.time() - time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.4268066049780428\n",
      "test score:  0.4308138700610733\n",
      "number of features used:  120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.596412420272827"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "lasso = Lasso(alpha = lassocv_alpha)#, max_iter = 10e6)\n",
    "lasso.fit(X_train_demo, y_train_demo)\n",
    "train_score = lasso.score(X_train_demo, y_train_demo)\n",
    "test_score = lasso.score(X_test_demo, y_test_demo)\n",
    "coef_used = np.sum(lasso.coef_ != 0)\n",
    "\n",
    "print('training score: ', train_score)\n",
    "print('test score: ', test_score)\n",
    "print('number of features used: ', coef_used)\n",
    "\n",
    "time.time() - time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = []\n",
    "\n",
    "used = []\n",
    "\n",
    "for i in range(len(lasso.coef_ )):\n",
    "    if lasso.coef_[i] == 0:\n",
    "        zeros += [i]\n",
    "    else:\n",
    "        used += [i]\n",
    "\n",
    "#test to see what it looks like:\n",
    "#X.iloc[0:10, used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "filtered = X.iloc[:, used]\n",
    "filtered['LOS'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'd2l'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-64f12d7b9577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#!pip install sklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgluon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgluon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'd2l'"
     ]
    }
   ],
   "source": [
    "# If pandas is not installed, please uncomment the following line:\n",
    "#!pip install pandas\n",
    "#!pip install sklearn\n",
    "%matplotlib inline\n",
    "import d2l\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = pd.read_pickle('bert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df = pd.merge(df_demo, bert, on='HADM_ID',\n",
    "              how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df['VEC'] = bert_df['VEC'].apply(lambda d: d if isinstance(d, np.ndarray) else [[0]]*768)\n",
    "bert_df = pd.merge(bert_df.iloc[:,:-1], \n",
    "                   pd.DataFrame(bert_df.VEC.values.tolist(), index= bert_df.HADM_ID).applymap(lambda x: x[0]),\n",
    "                   on='HADM_ID',\n",
    "                   how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post lasso data\n",
    "#filtered = pd.read_csv('filtered.csv') \n",
    "filtered['VEC'] = bert_df.iloc[:,bert_df.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if when u run lasso, there are different number of features,\n",
    "# just put labels as last column below.\n",
    "X = bert_df.drop(columns = ['LOS','DIED'])\n",
    "y = bert_df['LOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISSUE:\n",
    "can't figure out how to run with bert vector. take out below and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data dims: X: (47102, 1180), y: (47102,)\n",
      "test data dims: X: (11776, 1180), y: (11776,)\n",
      "Epoch 1/50\n",
      " 2560/47102 [>.............................] - ETA: 1:44 - loss: 35.9834"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/module/bucketing_module.py:408: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.00390625). Is this intended?\n",
      "  force_init=force_init)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47102/47102 [==============================] - 7s 156us/step - loss: 18.6139\n",
      "Epoch 2/50\n",
      "47102/47102 [==============================] - 1s 29us/step - loss: 9.8857\n",
      "Epoch 3/50\n",
      "47102/47102 [==============================] - 1s 30us/step - loss: 5.6056\n",
      "Epoch 4/50\n",
      "47102/47102 [==============================] - 1s 31us/step - loss: 3.8719\n",
      "Epoch 5/50\n",
      "47102/47102 [==============================] - 1s 30us/step - loss: 2.9423\n",
      "Epoch 6/50\n",
      "47102/47102 [==============================] - 1s 29us/step - loss: 2.3722\n",
      "Epoch 7/50\n",
      "47102/47102 [==============================] - 1s 30us/step - loss: 1.9966\n",
      "Epoch 8/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.7368\n",
      "Epoch 9/50\n",
      "47102/47102 [==============================] - 1s 32us/step - loss: 1.5688\n",
      "Epoch 10/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.4400\n",
      "Epoch 11/50\n",
      "47102/47102 [==============================] - 1s 32us/step - loss: 1.3777\n",
      "Epoch 12/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3814\n",
      "Epoch 13/50\n",
      "47102/47102 [==============================] - 1s 31us/step - loss: 1.3302\n",
      "Epoch 14/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.4178\n",
      "Epoch 15/50\n",
      "47102/47102 [==============================] - 2s 33us/step - loss: 1.3949\n",
      "Epoch 16/50\n",
      "47102/47102 [==============================] - 1s 32us/step - loss: 1.3716\n",
      "Epoch 17/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.4565\n",
      "Epoch 18/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3841\n",
      "Epoch 19/50\n",
      "47102/47102 [==============================] - 1s 32us/step - loss: 1.3518\n",
      "Epoch 20/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3629\n",
      "Epoch 21/50\n",
      "47102/47102 [==============================] - 2s 33us/step - loss: 1.3402\n",
      "Epoch 22/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3393\n",
      "Epoch 23/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3274\n",
      "Epoch 24/50\n",
      "47102/47102 [==============================] - 2s 33us/step - loss: 1.3349\n",
      "Epoch 25/50\n",
      "47102/47102 [==============================] - 1s 31us/step - loss: 1.3289\n",
      "Epoch 26/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.4321\n",
      "Epoch 27/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3472\n",
      "Epoch 28/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3468\n",
      "Epoch 29/50\n",
      "47102/47102 [==============================] - 1s 32us/step - loss: 1.3542\n",
      "Epoch 30/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3694\n",
      "Epoch 31/50\n",
      "47102/47102 [==============================] - 1s 31us/step - loss: 1.3534\n",
      "Epoch 32/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3459\n",
      "Epoch 33/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3548\n",
      "Epoch 34/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3643\n",
      "Epoch 35/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3509\n",
      "Epoch 36/50\n",
      "47102/47102 [==============================] - 1s 32us/step - loss: 1.4813\n",
      "Epoch 37/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.4163\n",
      "Epoch 38/50\n",
      "47102/47102 [==============================] - 1s 32us/step - loss: 1.4096\n",
      "Epoch 39/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.4037\n",
      "Epoch 40/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.4123\n",
      "Epoch 41/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.3997\n",
      "Epoch 42/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.4097\n",
      "Epoch 43/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.4075\n",
      "Epoch 44/50\n",
      "47102/47102 [==============================] - 1s 31us/step - loss: 1.4035\n",
      "Epoch 45/50\n",
      "47102/47102 [==============================] - 1s 32us/step - loss: 1.4362\n",
      "Epoch 46/50\n",
      "47102/47102 [==============================] - 1s 32us/step - loss: 1.4084\n",
      "Epoch 47/50\n",
      "47102/47102 [==============================] - 2s 32us/step - loss: 1.4100\n",
      "Epoch 48/50\n",
      "47102/47102 [==============================] - 2s 33us/step - loss: 1.4245\n",
      "Epoch 49/50\n",
      "47102/47102 [==============================] - 1s 31us/step - loss: 1.4068\n",
      "Epoch 50/50\n",
      "47102/47102 [==============================] - 1s 31us/step - loss: 1.4027\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "model = Sequential()\n",
    "model.add(Dense(512, kernel_initializer = 'normal', activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "#model.add(Dense(64, kernel_initializer = 'normal', activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1, \n",
    "                             momentum=0.99, epsilon=0.001, \n",
    "                             center=True, scale=True, \n",
    "                             beta_initializer='zeros', \n",
    "                             gamma_initializer='ones', \n",
    "                             moving_mean_initializer='zeros', \n",
    "                             moving_variance_initializer='ones', \n",
    "                             beta_regularizer=None, gamma_regularizer=None, \n",
    "                             beta_constraint=None, gamma_constraint=None))\n",
    "model.add(Dense(128, activation = 'relu', kernel_regularizer = regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1, \n",
    "                             momentum=0.99, epsilon=0.001, \n",
    "                             center=True, scale=True, \n",
    "                             beta_initializer='zeros', \n",
    "                             gamma_initializer='ones', \n",
    "                             moving_mean_initializer='zeros', \n",
    "                             moving_variance_initializer='ones', \n",
    "                             beta_regularizer=None, gamma_regularizer=None, \n",
    "                             beta_constraint=None, gamma_constraint=None))\n",
    "model.add(Dense(1))\n",
    "#model.compile(loss = 'rmse', optimizer = 'adam')\n",
    "model.compile(loss = 'msle', optimizer = 'adam')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f'training data dims: X: {X_train.shape}, y: {y_train.shape}')\n",
    "print(f'test data dims: X: {X_test.shape}, y: {y_test.shape}')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 50, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('Mean squared log error history')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('MSLE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286430027173913\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = predictions.reshape(len(y_test), )\n",
    "difference = predictions - y_test \n",
    "accuracy = sum(abs(difference) <= 48) /len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
